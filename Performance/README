## Performance Tests of the Subsampled Newton Optimizer

We conducted a series of performance tests for our custom model class, leveraging our Subsampled Newton Optimizer, across three datasets from the UCI database:
- [Iris Dataset](https://archive.ics.uci.edu/ml/datasets/iris)
- [Wine Dataset](https://archive.ics.uci.edu/ml/datasets/wine)
- [Dry Bean Dataset](https://archive.ics.uci.edu/dataset/602/dry+bean+dataset)

### Configuration
For the iris Dataset and the Wine Dataset tests, we configured the custom model with the following parameters:
- **Regularization Strength**: `1e-2`
- **Subsampling Parameter**: `0.9`
For the larger Dry Bean Dataset test regularization strength was also set to `1e-2`, but the subsampling parameter was set to `0.6`

We compared the performance of our model against two commonly used optimizers:
- **SGD (Stochastic Gradient Descent)**
- **Adam**

Both optimizers were set with a `batch_size` of `32` and a `learning_rate` of `0.01`.

### Testing Procedure
Each optimizer, including our custom Subsampled Newton Optimizer, was run for `100` epochs across `10` runs. The results are presented as plots showing the average loss convergence for each configuration.

### Neural Network Architectures
The tests were conducted on neural networks with varying depths to assess the adaptability and efficiency of the Subsampled Newton Optimizer:
- **Two-Layer Net**: A simple network with a two hidden layers, tested on the iris dataset (see plot: iris_2_layers).
- **Five-Layer Net**: A more complex network with five hidden layers, tested on the wine dataset (see plot: wine_5_layers).
- **Ten-Layer Net**: A (deep) network architecture with ten hidden layers, on the larger Dry Bean Dataset (see plot: dry_bean_10_layers).

### Performance
While both out model, as well as the standard optimizers would require fine tuning on their hyperparameters, depending on each problem, our performance tests with the fixed hyperparameter 
configurations, as mentioned above, shows promising results.  Nevertheless, while it  is performing better than the SGD Optimizer on the wine dataset ( i.e. the smallest tested net),
the average loss on the wine dataset does not converge to the minimum as expected, rather it shows some jumps (which are also present in the ADAM optimizer though).
For the Performance Test on the Dry Bean Dataset, our model, however, shows the highest average loss, while the SGD Optimizer converges fast to a lower loss (the ADAM Optimizer, however, does not 
converge to a minimum, but rather jumps and even increases). For Convenience another plot is included in the "Benchmark_Plots" Folder, displaying the Training and validation loss of our model, which is converging
to a minimum of about 1.83 when using the Dry Bean Dataset as input (see plot: tra_val_loss_model). The same hyperparameter configuration as in the dry_bean_10_layers test is used, only running for 25 epochs.



