# The following code was used to plot the performance of our custom subsampled newton method optimized model against SGD and ADAM

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
from tensorflow.autograph.experimental import do_not_convert

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.initializers import RandomNormal
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.optimizers import SGD 
from tensorflow.keras.optimizers import legacy as legacy_optimizers






# Define a function to create a baseline model with a specified optimizer
# Change the number of layers and their input and output shape depending on the dataset (its number of classes and number of features)
# CAVEAT: Adjust the layers both below create_model() and in the NewtonOptimizedModel below __init__()!
# For the plots, for each dataset, between first- and output. layer we chose 1, 4 and 19 layers respectively; each a Dense 10 neuron layer with tanh activation

#Example: iris_2_layer
def create_model(optimizer):
    model = Sequential([
        Dense(15, activation='tanh', input_shape=(4,)),
        Dense(10, activation='tanh'),
       # Dense(15, activation='tanh'),
        Dense(3, activation='softmax')
    ])
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    return model

class NewtonOptimizedModel(Model):
    def __init__(self, input_shape=(4,), subsampling_rate=0.9, num_classes=3):
        super(NewtonOptimizedModel, self).__init__()
        self.dense = Dense(15, activation='tanh', input_shape=input_shape, kernel_initializer=RandomNormal())
        self.dense1 = Dense(10, activation='tanh', kernel_initializer=RandomNormal())
        self.output_layer = Dense(num_classes, activation='softmax', kernel_initializer=RandomNormal())
        self.subsampling_rate = subsampling_rate

    def call(self, inputs):
        x = self.dense(inputs)
        x = self.dense1(x)
        return self.output_layer(x)

    def regularize_hessian(self, hessian, regularization_strength=1e-2):
        n = tf.shape(hessian)[-1]
        return hessian + tf.eye(n) * regularization_strength

    def train_step(self, data):
        x, y = data
        with tf.GradientTape(persistent=True) as tape:
            tape.watch(self.trainable_variables)
            y_pred = self(x, training=True)
            loss = self.compiled_loss(y, y_pred)

        subsampled_indices = np.random.choice(range(len(self.trainable_variables)), 
                                              size=int(np.floor(len(self.trainable_variables) * self.subsampling_rate)), 
                                              replace=False)
        update_norms = []

        for i, var in enumerate(self.trainable_variables):
            with tf.GradientTape() as hessian_tape:
                hessian_tape.watch(var)
                with tf.GradientTape() as grad_tape:
                    grad_tape.watch(var)
                    y_pred_inner = self(x, training=True)
                    loss_inner = self.compiled_loss(y, y_pred_inner)
                grad = grad_tape.gradient(loss_inner, var)

            if i in subsampled_indices:
                hessian = hessian_tape.jacobian(grad, var)
                var_size = tf.reduce_prod(var.shape)
                hessian_flat = tf.reshape(hessian, [var_size, var_size])
                hessian_reg = self.regularize_hessian(hessian_flat)
                inv_hessian = tf.linalg.inv(hessian_reg + tf.eye(var_size))# * 1e-4)
                update = tf.linalg.matmul(inv_hessian, tf.reshape(grad, [-1, 1]))
                update_reshaped = tf.reshape(update, var.shape)
                var.assign_sub(update_reshaped)
                update_norm = tf.norm(inv_hessian) #/ tf.norm(grad)
                update_norms.append(update_norm)

        avg_update_norm = tf.reduce_mean(update_norms) if update_norms else 0

        # Apply scaled gradient update to non-sampled variables
        for i, var in enumerate(self.trainable_variables):
            if i not in subsampled_indices:
                with tf.GradientTape() as grad_tape:
                    grad_tape.watch(var)
                    y_pred_inner = self(x, training=True)
                    loss_inner = self.compiled_loss(y, y_pred_inner)
                grad = grad_tape.gradient(loss_inner, var)
                scaled_update = grad * avg_update_norm
                var.assign_sub(scaled_update)

        self.compiled_metrics.update_state(y, y_pred)
        return {m.name: m.result() for m in self.metrics}
    
def newton_train_and_evaluate(X_train, y_train, X_test, y_test, epochs=100, runs=10, model_class=None):
    losses = []
    for _ in range(runs):
        model = model_class()  # Initialize the NewtonOptimizedModel
        model.compile(loss='categorical_crossentropy', metrics=['accuracy'])
        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=X_train.shape[0], epochs=epochs, verbose=0)
        losses.append(history.history['loss'])
    avg_loss = np.mean(losses, axis=0)
    return avg_loss

# Function to train the model and return loss history
def train_and_evaluate(optimizer, X_train, y_train, X_test, y_test, epochs=100, runs=10, model_class=None):
    losses = []
    for _ in range(runs):
        if model_class:
            model = model_class()  # Initialize custom model class if provided
        else:
            model = create_model(optimizer)
        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, verbose=0)
        losses.append(history.history['loss'])
    avg_loss = np.mean(losses, axis=0)
    return avg_loss

# Add the NewtonOptimizedModel definition here

    
# Load and prepare the dataset
# Change the path accordingly
file_path = '/path_to/iris.csv'   
data = pd.read_csv(file_path)
X = data.iloc[:, 0:4].values
y = data.iloc[:, 4].values
encoder = LabelEncoder()
encoder.fit(y)
encoded_Y = encoder.transform(y)
dummy_y = to_categorical(encoded_Y)
X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.2, random_state=42)

# Specify the learning rates for SGD and Adam
learning_rate = 0.01

# Initialize the SGD and Adam optimizers with the legacy version
sgd_optimizer = legacy_optimizers.SGD(learning_rate=0.01)
adam_optimizer = legacy_optimizers.Adam(learning_rate=0.01)

# Train and evaluate models with SGD, Adam, and NewtonOptimizedModel
sgd_loss = train_and_evaluate(sgd_optimizer, X_train, y_train, X_test, y_test)
adam_loss = train_and_evaluate(adam_optimizer, X_train, y_train, X_test, y_test)
# For the NewtonOptimizedModel, pass None as the optimizer and specify the model class
newton_loss = newton_train_and_evaluate(X_train, y_train, X_test, y_test, model_class=NewtonOptimizedModel)

# Plot the averaged losses
epochs = range(1, 101)
plt.plot(epochs, sgd_loss, label='SGD Loss')
plt.plot(epochs, adam_loss, label='Adam Loss')
plt.plot(epochs, newton_loss, label='Newton Optimized Loss')  # Add NewtonOptimizedModel loss plot
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

